{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "erm = \"You are an expert suggestion generator.\\nYou generate three random questions a user could potentially ask to LLM, helping the user get started with a conversation.\\nFor each of the questions you generate, you also generate a bucket title this question / request falls under.\\nSome bucket examples might be:\\n- Programming Questions\\n- Fun Facts\\n- General Knowledge\\n- Story Creation\\n- Jokes and Humor\\n- etc\\n\\nResponse with three questions and their corresponding bucket as a json payload. Make the questions detailed an unique.\\n\\nExample response format:\\n{\\n  \\\"suggestions\\\": [\\n    {\\n      \\\"bucket\\\": \\\"Programming Questions\\\",\\n      \\\"question\\\": \\\"How do I reverse a string in Python?\\\"\\n    },\\n    {\\n      \\\"bucket\\\": \\\"Fun Facts\\\",\\n      \\\"question\\\": \\\"What are some interesting facts about the universe?\\\"\\n    },\\n    {\\n      \\\"bucket\\\": \\\"Story Creation\\\",\\n      \\\"question\\\": \\\"Can you help me write a short story about a time-traveling detective?\\\"\\n    }\\n  ]\\n}\\n\\nOnly repond with the JSON payload surounded in triple back ticks ``` and nothing else.\"\n",
    "\n",
    "def print_json(response: requests.Response):\n",
    "    print(response.status_code)\n",
    "    try:\n",
    "        json_data = response.json()\n",
    "        print(json.dumps(json_data, indent=4))\n",
    "    except json.JSONDecodeError:\n",
    "        print(response.content.decode(\"utf8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Unknown error -> {e}\")\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "login = session.post(\n",
    "    \"http://127.0.0.1:8000/api/v1/login/\",\n",
    "    data=json.dumps({\"username\": \"ethan\", \"password\": \"ethan\"}),\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    },\n",
    ")\n",
    "\n",
    "token = login.json().get(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\n",
      "    \"id\": 66,\n",
      "    \"recoverable\": false,\n",
      "    \"model\": {\n",
      "        \"id\": 2,\n",
      "        \"name\": \"llama3.2-vision:latest\",\n",
      "        \"model\": \"llama3.2-vision:latest\",\n",
      "        \"liked\": false,\n",
      "        \"provider\": \"ollama\",\n",
      "        \"color\": \"Gray\"\n",
      "    },\n",
      "    \"content_variations\": [\n",
      "        {\n",
      "            \"id\": 115,\n",
      "            \"content\": \"The image is a meme with three panels, each featuring a man in a different setting. The first panel shows a man holding up a microplastic, with the caption \\\"hello, food, hold the microplastics.\\\" The second panel depicts a man in a fast-food restaurant uniform, with the text \\\"microplastics in everything.\\\" The third panel features a man driving a car, pointing to something outside the window, accompanied by the phrase \\\"understandable we reap what we sow.\\\"\\n\\nThe image appears to be a commentary on the prevalence of microplastics in our environment and their potential impact on human health. It suggests that even seemingly innocuous everyday actions, such as eating fast food or driving a car, may contribute to the problem of microplastic pollution. The use of humor and irony adds a layer of critique to the message, implying that the consequences of our actions are not just environmental but also moral.\\n\\nOverall, the image presents a thought-provoking commentary on the interconnectedness of human behavior and the natural world, encouraging viewers to consider the broader implications of their choices.\"\n",
      "        }\n",
      "    ],\n",
      "    \"generated_by\": {\n",
      "        \"id\": 67,\n",
      "        \"recoverable\": false,\n",
      "        \"content\": \"extract the text from the message!\",\n",
      "        \"created_at\": \"2024-11-23T23:03:24.005767Z\",\n",
      "        \"image\": \"http://127.0.0.1:8000/api/v1/media/user_message_images/Screenshot_2024-10-09_194915_x1K7Rr2.png\",\n",
      "        \"is_deleted\": false,\n",
      "        \"deleted_at\": null,\n",
      "        \"conversation\": \"852b0f9b-3a87-499e-a65b-34314ced02eb\"\n",
      "    },\n",
      "    \"provider\": \"ollama\",\n",
      "    \"created_at\": \"2024-11-23T23:03:35.534558Z\",\n",
      "    \"liked\": false,\n",
      "    \"is_deleted\": false,\n",
      "    \"deleted_at\": null,\n",
      "    \"conversation\": \"852b0f9b-3a87-499e-a65b-34314ced02eb\",\n",
      "    \"type\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\n",
    "    url=\"http://127.0.0.1:8000/api/v1/messages/assistant/66/\",\n",
    "    headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Token {token}\"},\n",
    ")\n",
    "\n",
    "print_json(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
